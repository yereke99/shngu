# pdf_processor.py
import os
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
import json
from pathlib import Path
import hashlib

class PDFDynamogramProcessor:
    """
    Process PDF files containing dynamogram images and extract them for training/prediction
    """
    
    def __init__(self, data_folder="data", processed_folder="processed_images"):
        self.data_folder = Path(data_folder)
        self.processed_folder = Path(processed_folder)
        self.processed_folder.mkdir(exist_ok=True)
        
        # Create subfolders for each class
        for i in range(1, 31):
            (self.processed_folder / f"class_{i}").mkdir(exist_ok=True)
        
        # Load class definitions from your documentation
        self.class_definitions = self._load_class_definitions()
        
    def _load_class_definitions(self):
        """Load the 30 pump condition definitions"""
        return {
            1: "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ø—Ä–∏—Ç–æ–∫ –∂–∏–¥–∫–æ—Å—Ç–∏",
            2: "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ø—Ä–∏—Ç–æ–∫ –∂–∏–¥–∫–æ—Å—Ç–∏ –∏ –ø–æ–≤—ã—à–µ–Ω–Ω–æ–µ —Ç—Ä–µ–Ω–∏–µ", 
            3: "–ì–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ",
            4: "–°–∏–ª—å–Ω–∞—è –≤–∏–±—Ä–∞—Ü–∏—è",
            5: "–í–Ω–µ–∑–∞–ø–Ω—ã–µ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è –ø—Ä–∏—Ç–æ–∫–∞ –∂–∏–¥–∫–æ—Å—Ç–∏",
            6: "–í–Ω–µ–∑–∞–ø–Ω–æ–µ –æ–±—â–µ–µ –≥–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ",
            7: "–í–Ω–µ–∑–∞–ø–Ω–∞—è —É—Ç–µ—á–∫–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ—Ö–æ–¥–Ω–æ–π –∫–ª–∞–ø–∞–Ω",
            8: "–í—ã—Ç—è–≥–∏–≤–∞–Ω–∏–µ –ø–ª—É–Ω–∂–µ—Ä–∞ –∏–∑ —Ü–∏–ª–∏–Ω–¥—Ä–∞",
            9: "–í–Ω–µ–∑–∞–ø–Ω—ã–π –æ–±—Ä—ã–≤ —à—Ç–∞–Ω–≥",
            10: "–†–∞–±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            11: "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ø—Ä–∏—Ç–æ–∫ –∂–∏–¥–∫–æ—Å—Ç–∏",
            12: "–£–¥–∞—Ä –ø–ª—É–Ω–∂–µ—Ä–∞ –æ –Ω–∞—Å–æ—Å",
            13: "–ì–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ —Å –≤–∏–±—Ä–∞—Ü–∏–µ–π",
            14: "–ü–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ –æ—Ç–∫–∞–∑ —à—Ç–∞–Ω–≥–æ–≤–æ–≥–æ –∑–∞—Ü–µ–ø–∞",
            15: "–í–Ω–µ–∑–∞–ø–Ω—ã–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è –ø—Ä–∏—Ç–æ–∫–∞ –∂–∏–¥–∫–æ—Å—Ç–∏",
            16: "–í–Ω–µ–∑–∞–ø–Ω–æ–µ —Å–∏–ª—å–Ω–æ–µ –≥–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ, –≤–æ–∑–¥—É—à–Ω–∞—è –ø—Ä–æ–±–∫–∞",
            17: "–í–Ω–µ–∑–∞–ø–Ω—ã–π –æ—Ç–∫–∞–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è –ø—Ä–∏—ë–º–Ω–æ–≥–æ –∫–ª–∞–ø–∞–Ω–∞",
            18: "–í–Ω–µ–∑–∞–ø–Ω–∞—è —É—Ç–µ—á–∫–∞ –≤ –∫–æ–ª–æ–Ω–Ω–µ –ù–ö–¢",
            19: "–ü–æ–ø–∞–¥–∞–Ω–∏–µ –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞ –≤ –Ω–∞—Å–æ—Å",
            20: "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∏—Ç–æ–∫ (—Ñ–æ–Ω—Ç–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)",
            21: "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ø—Ä–∏—Ç–æ–∫ –∂–∏–¥–∫–æ—Å—Ç–∏ —Å –≤–∏–±—Ä–∞—Ü–∏–µ–π",
            22: "–£–¥–∞—Ä –ø–ª—É–Ω–∂–µ—Ä–∞ –∏ –≤–∏–±—Ä–∞—Ü–∏—è",
            23: "–í–∏–±—Ä–∞—Ü–∏—è",
            24: "–†–∞–±–æ—Ç–∞ –ø–æ–¥ –ø–æ–ª–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π",
            25: "–í–Ω–µ–∑–∞–ø–Ω–æ–µ —Ä–µ–∑–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–∏—Ç–æ–∫–∞ –∂–∏–¥–∫–æ—Å—Ç–∏",
            26: "–í–Ω–µ–∑–∞–ø–Ω—ã–π –æ—Ç–∫–∞–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è –ø—Ä–æ—Ö–æ–¥–Ω–æ–≥–æ –∫–ª–∞–ø–∞–Ω–∞",
            27: "–í–Ω–µ–∑–∞–ø–Ω–∞—è —É—Ç–µ—á–∫–∞ —á–µ—Ä–µ–∑ –ø—Ä–∏—ë–º–Ω—ã–π –∫–ª–∞–ø–∞–Ω",
            28: "–í–Ω–µ–∑–∞–ø–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—è",
            29: "–°–∏–ª—å–Ω–æ–µ –≥–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ",
            30: "–£—Ç–µ—á–∫–∞ –≤ –Ω–∞—Å–æ—Å–µ"
        }
    
    def extract_images_from_pdf(self, pdf_path, class_id):
        """
        Extract dynamogram images from PDF file
        """
        try:
            doc = fitz.open(pdf_path)
            extracted_images = []
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                
                # Get images from page
                image_list = page.get_images()
                
                for img_index, img in enumerate(image_list):
                    # Get image data
                    xref = img[0]
                    pix = fitz.Pixmap(doc, xref)
                    
                    if pix.n - pix.alpha < 4:  # GRAY or RGB
                        # Convert to PIL Image
                        img_data = pix.tobytes("ppm")
                        pil_image = Image.open(io.BytesIO(img_data))
                        
                        # Generate unique filename
                        img_hash = hashlib.md5(img_data).hexdigest()[:8]
                        filename = f"class_{class_id}_page_{page_num}_img_{img_index}_{img_hash}.png"
                        
                        # Save to class folder
                        save_path = self.processed_folder / f"class_{class_id}" / filename
                        pil_image.save(save_path)
                        extracted_images.append(str(save_path))
                        
                        print(f"Extracted: {filename}")
                    
                    pix = None
            
            doc.close()
            return extracted_images
            
        except Exception as e:
            print(f"Error processing {pdf_path}: {str(e)}")
            return []
    
    def process_all_pdfs(self):
        """
        Process all PDF files in the data folder (1.pdf to 30.pdf)
        """
        processed_info = {}
        
        for class_id in range(1, 31):
            pdf_file = self.data_folder / f"{class_id}.pdf"
            
            if pdf_file.exists():
                print(f"Processing {pdf_file} for class {class_id}...")
                extracted_images = self.extract_images_from_pdf(pdf_file, class_id)
                
                processed_info[class_id] = {
                    'class_name': self.class_definitions[class_id],
                    'pdf_file': str(pdf_file),
                    'extracted_images': extracted_images,
                    'image_count': len(extracted_images)
                }
                
                print(f"‚úÖ Class {class_id}: {len(extracted_images)} images extracted")
            else:
                print(f"‚ö†Ô∏è  File {pdf_file} not found")
                processed_info[class_id] = {
                    'class_name': self.class_definitions[class_id],
                    'pdf_file': str(pdf_file),
                    'extracted_images': [],
                    'image_count': 0
                }
        
        # Save processing info
        info_file = self.processed_folder / "processing_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(processed_info, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìä Processing complete! Info saved to {info_file}")
        return processed_info
    
    def get_dataset_info(self):
        """
        Get information about the processed dataset
        """
        info_file = self.processed_folder / "processing_info.json"
        if info_file.exists():
            with open(info_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def create_training_split(self, train_ratio=0.8):
        """
        Create train/validation split from processed images
        """
        import random
        
        dataset_info = self.get_dataset_info()
        if not dataset_info:
            print("No dataset info found. Run process_all_pdfs() first.")
            return None
        
        train_data = []
        val_data = []
        
        for class_id, info in dataset_info.items():
            if isinstance(class_id, str):
                class_id = int(class_id)
            
            images = info['extracted_images']
            if len(images) == 0:
                continue
            
            # Shuffle images
            random.shuffle(images)
            split_idx = int(len(images) * train_ratio)
            
            # Split data
            train_images = images[:split_idx]
            val_images = images[split_idx:]
            
            # Add to datasets
            for img_path in train_images:
                train_data.append((img_path, class_id - 1))  # 0-based indexing
            
            for img_path in val_images:
                val_data.append((img_path, class_id - 1))
        
        print(f"üìä Dataset split:")
        print(f"   Training samples: {len(train_data)}")
        print(f"   Validation samples: {len(val_data)}")
        
        return train_data, val_data

# Example usage
if __name__ == "__main__":
    import io
    
    processor = PDFDynamogramProcessor()
    
    # Process all PDFs
    info = processor.process_all_pdfs()
    
    # Create training split
    train_data, val_data = processor.create_training_split()
    
    print("\nüéØ Ready for training!")